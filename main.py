import streamlit as st
import openai
import pandas as pd
from tqdm import tqdm
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.llms import OpenAI
import my_key

# è®¾ç½®é¡µé¢å®½åº¦ä¸ºè¾ƒå®½çš„å¸ƒå±€
st.set_page_config(layout="wide")

def analyze_resume(jd, resume, options):
    df = analyze_str(resume, options)
    df_string = df.applymap(lambda x: ', '.join(x) if isinstance(x, list) else x).to_string(index=False)
    st.write("OpenAIç»¼åˆåˆ†æ..")
    summary_question = f"èŒä½è¦æ±‚æ˜¯ï¼š{{{jd}}}" + f"ç®€å†æ¦‚è¦æ˜¯ï¼š{{{df_string}}}" + "ï¼Œè¯·ç›´æ¥è¿”å›è¯¥åº”è˜å²—ä½å€™é€‰äººåŒ¹é…åº¦æ¦‚è¦ï¼ˆæ§åˆ¶åœ¨200å­—ä»¥å†…ï¼‰;'"
    summary = ask_openAI(summary_question)
    df.loc[len(df)] = ['ç»¼åˆæ¦‚è¦', summary]
    extra_info = "æ‰“åˆ†è¦æ±‚ï¼šå›½å†…top10å¤§å­¦+3åˆ†ï¼Œ985å¤§å­¦+2åˆ†ï¼Œ211å¤§å­¦+1åˆ†ï¼Œå¤´éƒ¨ä¼ä¸šç»å†+2åˆ†ï¼ŒçŸ¥åä¼ä¸š+1åˆ†ï¼Œæµ·å¤–èƒŒæ™¯+3åˆ†ï¼Œå¤–ä¼èƒŒæ™¯+1åˆ†ã€‚ "
    score_question = f"èŒä½è¦æ±‚æ˜¯ï¼š{{{jd}}}" + f"ç®€å†æ¦‚è¦æ˜¯ï¼š{{{df.to_string(index=False)}}}" + "ï¼Œè¯·ç›´æ¥è¿”å›è¯¥åº”è˜å²—ä½å€™é€‰äººçš„åŒ¹é…åˆ†æ•°ï¼ˆ0-100ï¼‰ï¼Œè¯·ç²¾ç¡®æ‰“åˆ†ä»¥æ–¹ä¾¿å…¶ä»–å€™é€‰äººå¯¹æ¯”æ’åºï¼Œ'" + extra_info
    score = ask_openAI(score_question)
    df.loc[len(df)] = ['åŒ¹é…å¾—åˆ†', score]

    return df

def ask_openAI(question):
    response = openai.Completion.create(
        engine="text-davinci-003",
        prompt=question,
        max_tokens=400,
        n=1,
        stop=None,
        temperature=0,
    )
    return response.choices[0].text.strip()

def analyze_str(resume, options):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=600,
        chunk_overlap=100,
        length_function=len
    )
    chunks = text_splitter.split_text(resume)

    embeddings = OpenAIEmbeddings(openai_api_key=my_key.get_key())
    knowledge_base = FAISS.from_texts(chunks, embeddings)

    df_data = [{'option': option, 'value': []} for option in options]
    st.write("ä¿¡æ¯æŠ“å–")

    # åˆ›å»ºè¿›åº¦æ¡å’Œç©ºå…ƒç´ 
    progress_bar = st.progress(0)
    option_status = st.empty()

    for i, option in tqdm(enumerate(options), desc="ä¿¡æ¯æŠ“å–ä¸­", unit="é€‰é¡¹", ncols=100):
        question = f"è¿™ä¸ªåº”è˜è€…çš„{option}æ˜¯ä»€ä¹ˆï¼Œè¯·ç²¾ç®€è¿”å›ç­”æ¡ˆï¼Œæœ€å¤šä¸è¶…è¿‡250å­—ï¼Œå¦‚æœæŸ¥æ‰¾ä¸åˆ°ï¼Œåˆ™è¿”å›'æœªæä¾›'"
        docs = knowledge_base.similarity_search(question)
        llm = OpenAI(openai_api_key=my_key.get_key(), temperature=0.3, model_name="text-davinci-003", max_tokens="2000")
        chain = load_qa_chain(llm, chain_type="stuff")
        response = chain.run(input_documents=docs, question=question )
        df_data[i]['value'] = response
        option_status.text(f"æ­£åœ¨æŸ¥æ‰¾ä¿¡æ¯ï¼š{option}")

        # æ›´æ–°è¿›åº¦æ¡
        progress = (i + 1) / len(options)
        progress_bar.progress(progress)

    df = pd.DataFrame(df_data)
    st.success("ç®€å†è¦ç´ å·²è·å–")
    return df

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.title("ğŸš€ GPTæ‹›è˜åˆ†ææœºå™¨äºº")
st.subheader("ğŸª¢ Langchain + ğŸ OpenAI")

# è®¾ç½®é»˜è®¤çš„JDå’Œç®€å†ä¿¡æ¯
default_jd = "ä¸šåŠ¡æ•°æ®åˆ†æå¸ˆJD å²—ä½èŒè´£ï¼š..."
default_resume = "åº”è˜ç®€å† ä¸ªäººä¿¡æ¯ï¼š..."

# è¾“å…¥JDä¿¡æ¯
jd_text = st.text_area("ã€å²—ä½ä¿¡æ¯ã€‘", height=100, value=default_jd)

# è¾“å…¥ç®€å†ä¿¡æ¯
resume_text = st.text_area("ã€åº”è˜ç®€å†ã€‘", height=100, value=default_resume)

# å‚æ•°è¾“å…¥
options = ["å§“å", "è”ç³»å·ç ", "æ€§åˆ«", "å¹´é¾„", "å·¥ä½œå¹´æ•°ï¼ˆæ•°å­—ï¼‰", "æœ€é«˜å­¦å†", "æœ¬ç§‘å­¦æ ¡åç§°", "ç¡•å£«å­¦æ ¡åç§°", "æ˜¯å¦åœ¨èŒ", "å½“å‰èŒåŠ¡", "å†å²ä»»èŒå…¬å¸åˆ—è¡¨", "æŠ€æœ¯èƒ½åŠ›", "ç»éªŒç¨‹åº¦", "ç®¡ç†èƒ½åŠ›"]
selected_options = st.multiselect("è¯·é€‰æ‹©é€‰é¡¹", options, default=options)

# åˆ†ææŒ‰é’®
if st.button("å¼€å§‹åˆ†æ"):
    df = analyze_resume(jd_text, resume_text, selected_options)
    st.subheader("ç»¼åˆåŒ¹é…å¾—åˆ†ï¼š"+ df.loc[df['option'] == 'åŒ¹é…å¾—åˆ†', 'value'].values[0])
    st.subheader("ç»†é¡¹å±•ç¤ºï¼š")
    st.table(df)
